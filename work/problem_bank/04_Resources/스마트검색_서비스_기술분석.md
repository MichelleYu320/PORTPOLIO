# 스마트검색 서비스 - 기술 분석 및 구현 방안
> 작성일: 2025-09-11  
> 문제은행 플랫폼 스마트검색 시스템 상세 분석  

---

## 🔍 **멀티모달 검색 vs Vector DB - 개념 정리**

### **멀티모달 검색 (Multimodal Search)**
> **여러 형태의 데이터(텍스트, 이미지, 수식)를 함께 검색하는 방식**

```yaml
검색 대상:
  - 텍스트: 문제 발문, 지문, 선택지
  - 이미지: 그래프, 도형, 사진  
  - 수식: LaTeX, MathML
  - 혼합: 텍스트+이미지+수식이 함께 있는 문제

검색 방식 예시:
  사용자가 이미지를 업로드 → "이런 그래프와 비슷한 문제 찾기"
  수식 입력 → "이 공식을 사용하는 문제 찾기"  
  텍스트+이미지 → "원의 방정식 + 그래프가 있는 문제"
```

### **Vector DB (Vector Database)**
> **데이터를 벡터로 변환해서 저장하고 유사도로 검색하는 저장/검색 방식**

```yaml
데이터 처리:
  문제 텍스트 → [0.1, 0.5, -0.3, ...] (768차원 벡터)
  이미지 → [0.2, -0.1, 0.8, ...] (512차원 벡터)
  수식 → [0.4, 0.2, -0.6, ...] (256차원 벡터)

검색 방식:
  쿼리를 벡터로 변환 → 기존 벡터들과 유사도 계산 → 가장 유사한 것들 반환
```

### **둘의 관계**
```
멀티모달 검색 = 여러 형태 데이터를 검색 (what)
Vector DB = 벡터 기반으로 저장/검색 (how)

멀티모달 검색을 구현하려면:
  1. 각 데이터 타입을 벡터로 변환 (임베딩)
  2. Vector DB에 저장
  3. 쿼리 시 적절한 벡터로 변환해서 검색
```

---

## 🎯 **문제은행 스마트검색 - 4가지 검색 방식**

### **1️⃣ 자연어 검색** 
```yaml
목적: "서울 고3 중간고사용 어려운 수학 문제 10개"
구현: 자연어 → 구조화된 쿼리 변환

Phase 1 (태그 기반):
  자연어 → GPT 파싱 → 기존 태그 검색
  예상 정확도: 80-85%
  구현 기간: 2-3개월
  비용: 매우 낮음

Phase 2 (Vector 보강):  
  자연어 → 의미 벡터 → Vector DB 검색
  예상 정확도: 90-95%
  구현 기간: 6개월
  비용: 중간
```

### **2️⃣ 유사문항 검색**
```yaml
목적: "이 문제와 비슷한 문제 찾기"
특징: Vector DB가 거의 필수

태그 방식의 한계:
  - "이차함수 최솟값" ≠ "포물선 꼭짓점" (사실상 같은 개념)
  - "직육면체 부피" ≠ "물탱크 용량" (같은 수학 구조)

Vector 방식의 우위:
  - 의미적 유사도: 표현이 달라도 같은 개념 인식
  - 구조적 유사도: 다른 소재라도 수학적 구조 인식
  예상 정확도: 85-90%
```

### **3️⃣ 멀티모달 검색**
```yaml
목적: 텍스트 + 이미지 + 수식 통합 검색
구현 방식: 각 모달리티를 벡터화 후 통합

검색 시나리오:
  1. 이미지 기반: 그래프 이미지 업로드 → 유사한 그래프 문제
  2. 수식 기반: LaTeX 입력 → 해당 공식 사용 문제  
  3. 혼합 검색: "일차함수" + 그래프 이미지 → 정확한 매칭

기술 스택:
  - 텍스트: OpenAI text-embedding-3-small
  - 이미지: CLIP, Vision Transformer
  - 수식: MathBERT, 수식 전용 임베딩
```

### **4️⃣ 복합 조건 검색**
```yaml
목적: 여러 조건을 조합한 정밀 검색
구현: 하이브리드 방식 (태그 + Vector)

검색 플로우:
  1차 필터링: 태그 기반 (학년, 과목, 난이도)
  2차 정밀검색: Vector 기반 (의미, 유사도)
  3차 후처리: 사용 이력, 인기도 반영

예시: "고2 수학 중간 범위에서 + 피타고라스 개념 + 실생활 응용"
```

---

## 🏗️ **단계별 구현 전략**

### **Phase 1: Smart Tag Search** (즉시 시작)
```yaml
구현 내용:
  - GPT 기반 자연어 파싱
  - 기존 CBS 태그 시스템 활용  
  - 기본 유사문항 (태그 매칭 기반)

기술 스택:
  - LLM: GPT-3.5 Turbo (자연어 파싱)
  - DB: 기존 PostgreSQL + 인덱싱
  - Cache: Redis (빈번 검색 캐싱)

예상 성과:
  - 자연어 검색 정확도: 80-85%
  - 유사문항 정확도: 40-50% (한계 있음)
  - 구현 기간: 2-3개월
  - 월 운영비용: $50-100
```

### **Phase 2: Hybrid Vector Search** (6개월 후)
```yaml
구현 내용:
  - 선별적 Vector 구축 (신규/인기 문제)
  - 하이브리드 검색 (태그 + Vector)
  - 기본 멀티모달 (텍스트 중심)

기술 스택:
  - Vector DB: Pinecone, Weaviate, Chroma
  - Embedding: OpenAI text-embedding-3-small
  - 검색: Elasticsearch + Vector 하이브리드

벡터화 전략:
  - 신규 문제: 실시간 임베딩
  - 기존 문제: 인기도 순 점진적 처리
  - 전체 대상: 월 1만개 → 연 12만개

예상 성과:
  - 자연어 검색: 90-95%
  - 유사문항: 85-90%  
  - 월 운영비용: $200-500
```

### **Phase 3: Full Multimodal** (12개월 후)
```yaml
구현 내용:
  - 완전 멀티모달 검색 (텍스트+이미지+수식)
  - AI 기반 개인화 추천
  - 실시간 학습 및 피드백 반영

기술 스택:
  - 이미지: CLIP, Vision Transformer  
  - 수식: MathBERT, LaTeX 전용 임베딩
  - 통합: 멀티모달 퓨전 모델

예상 성과:
  - 멀티모달 검색 정확도: 85-90%
  - 개인화 추천 정확도: 90-95%
  - 월 운영비용: $500-1000
```

---

## 💰 **비용 분석**

### **Vector DB 구축 비용**
```yaml
초기 구축:
  - 100만 문제 임베딩: $100 (1회)
  - Vector DB 설정: 개발비용 ($10K)
  
운영 비용 (월):
  - 신규 문제 임베딩: 1만개 × $0.0001 = $1
  - Vector DB 호스팅: $200-500 (Pinecone 기준)
  - 검색 API 호출: $50-200 (사용량 기준)

저장소:
  - 100만 문제 × 1.5KB = 1.5GB
  - 연간 증가: 12만 문제 × 1.5KB = 180MB
```

### **멀티모달 추가 비용**
```yaml
이미지 처리:
  - 이미지 임베딩: 문제당 $0.001
  - 10만 이미지 = $100 (1회)
  
수식 처리:
  - 수식 파싱 + 임베딩: 문제당 $0.0005  
  - LaTeX 변환: 별도 비용 없음 (오픈소스)
```

---

## 🎯 **기술 선택 가이드**

### **즉시 필요한 기능별 추천**

| 기능 | 권장 구현 방식 | 이유 |
|------|---------------|------|
| **자연어 검색** | Phase 1 (태그 기반) | 80% 케이스는 태그로 해결 가능, 빠른 구현 |
| **유사문항 검색** | Phase 2 (Vector 필수) | 의미적 유사도 없이는 한계 명확 |
| **멀티모달 검색** | Phase 3 (장기) | 기술 복잡도 높음, 사용 빈도 상대적 낮음 |
| **실시간 추천** | Phase 2 (Vector) | 사용 패턴 학습 + 의미적 매칭 필요 |

### **ROI 기준 우선순위**
```yaml
1순위: 자연어 검색 (태그 기반)
  - 개발 용이성: ⭐⭐⭐⭐⭐
  - 비즈니스 임팩트: ⭐⭐⭐⭐⭐  
  - 사용자 만족도: ⭐⭐⭐⭐

2순위: 유사문항 검색 (Vector)
  - 개발 용이성: ⭐⭐⭐
  - 비즈니스 임팩트: ⭐⭐⭐⭐⭐
  - 사용자 만족도: ⭐⭐⭐⭐⭐

3순위: 멀티모달 검색
  - 개발 용이성: ⭐⭐
  - 비즈니스 임팩트: ⭐⭐⭐
  - 사용자 만족도: ⭐⭐⭐⭐
```

---

## 🔧 **구현 상세 가이드**

### **Phase 1: Smart Tag Search 구현**
```python
# 자연어 쿼리 파싱
def parse_natural_query(query: str) -> dict:
    prompt = f"""
    다음 자연어 검색을 구조화된 쿼리로 변환하세요:
    "{query}"
    
    반환 형식:
    {{
        "학년": "고등학교 3학년",
        "과목": "수학", 
        "지역": "서울",
        "시험유형": "중간고사",
        "난이도": "상",
        "개수": 10,
        "개념": ["피타고라스 정리"]
    }}
    """
    
    response = openai.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}]
    )
    return json.loads(response.choices[0].message.content)

# 기존 태그 시스템과 연동
def search_by_tags(parsed_query: dict) -> List[Question]:
    query_builder = QuestionQuery()
    
    if parsed_query.get("학년"):
        query_builder.grade(parsed_query["학년"])
    if parsed_query.get("과목"):
        query_builder.subject(parsed_query["과목"]) 
    # ... 다른 조건들
    
    return query_builder.execute()
```

### **Phase 2: Vector Search 구현**  
```python
# 문제 임베딩 생성
def create_question_embedding(question: Question) -> List[float]:
    # 문제 전문을 하나의 텍스트로 결합
    full_text = f"""
    문제: {question.problem_text}
    선택지: {' '.join(question.choices)}
    해설: {question.explanation}
    개념: {', '.join(question.concepts)}
    """
    
    response = openai.embeddings.create(
        model="text-embedding-3-small",
        input=full_text
    )
    return response.data[0].embedding

# 유사문항 검색
def find_similar_questions(target_id: str, limit: int = 10):
    # 1단계: 태그 기반 후보 선별
    target = Question.get(target_id)
    candidates = Question.filter(
        subject=target.subject,
        grade=target.grade,
        difficulty=target.difficulty
    )
    
    # 2단계: Vector 유사도 계산  
    target_vector = get_question_embedding(target_id)
    similarities = []
    
    for candidate in candidates:
        if candidate.id == target_id:
            continue
            
        candidate_vector = get_question_embedding(candidate.id)
        similarity = cosine_similarity([target_vector], [candidate_vector])[0][0]
        similarities.append((candidate, similarity))
    
    # 3단계: 유사도 순 정렬
    return sorted(similarities, key=lambda x: x[1], reverse=True)[:limit]
```

---

## 📊 **예상 성과 및 KPI**

### **정량적 지표**
```yaml
검색 정확도:
  - 자연어 검색: 80% (Phase 1) → 95% (Phase 2)
  - 유사문항: 40% (태그) → 85% (Vector)
  - 멀티모달: 85% (Phase 3)

성능 지표:
  - 응답 시간: <200ms (p95)
  - 동시 사용자: 1000+ 지원
  - 가용성: 99.9%

비즈니스 지표:
  - 검색 사용량: 기존 대비 300% 증가 예상
  - 문제 재사용률: 50% → 80% 증가
  - 사용자 만족도: NPS 70+ 목표
```

### **정성적 효과**
- **사용자 경험 혁신**: "생각하는 대로 검색" 실현
- **업무 효율성**: 문제 선별 시간 90% 단축  
- **콘텐츠 활용도**: 묻혀있던 좋은 문제 재발굴
- **플랫폼 차별화**: 국내 유일의 AI 검색 시스템

---

## 🎯 **결론 및 권고사항**

### **핵심 메시지**
1. **자연어 검색**: 태그 기반으로 시작, Vector로 고도화
2. **유사문항 검색**: Vector DB 필수, 하이브리드 방식 권장  
3. **멀티모달**: 장기 목표, 단계적 접근 필요

### **실행 로드맵**
```
3개월: Phase 1 완성 (자연어 검색)
6개월: Phase 2 베타 (Vector 유사문항)  
12개월: Phase 3 론칭 (멀티모달)
```

### **성공 요소**
- **기존 인프라 최대한 활용**: CBS 태그 시스템 연계
- **점진적 Vector화**: 전체 구축 부담 최소화
- **사용자 피드백 반영**: 지속적 정확도 개선

**스마트검색은 문제은행 플랫폼의 핵심 차별화 요소가 될 것입니다.**

---

*본 문서는 문제은행 스마트검색 서비스 구축을 위한 기술 분석서입니다.*